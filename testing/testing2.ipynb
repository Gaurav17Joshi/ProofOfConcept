{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Testing2"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/gaurav/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/stingray/utils.py:35: UserWarning: pyfftw not installed. Using standard scipy fft\n","  warnings.warn(\"pyfftw not installed. Using standard scipy fft\")\n","/Users/gaurav/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/stingray/utils.py:50: UserWarning: Numba not installed. Faking it\n","  warnings.warn(\"Numba not installed. Faking it\")\n","INFO[2023-07-20 01:13:07,070]: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n","INFO[2023-07-20 01:13:07,071]: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n","INFO[2023-07-20 01:13:07,071]: Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n"]}],"source":["# Required libraries\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","try:\n","    import jax\n","except ImportError:\n","    raise ImportError(\"Jax not installed\")\n","\n","import jax.numpy as jnp\n","import functools\n","import tensorflow_probability.substrates.jax as tfp\n","\n","from jax import jit, random, vmap\n","jax.config.update(\"jax_enable_x64\", True)\n","\n","from tinygp import GaussianProcess, kernels\n","from stingray import Lightcurve\n","\n","try:\n","    from jaxns import ExactNestedSampler\n","    from jaxns import TerminationCondition\n","\n","    # from jaxns import analytic_log_evidence\n","    from jaxns import Prior, Model\n","    from jaxns.utils import resample\n","    can_sample = True\n","except ImportError:\n","    can_sample = False\n","\n","\n","from jax import random\n","\n","# Have to make for all external dependencies\n","try:\n","    from tqdm import tqdm as show_progress\n","except ImportError:\n","\n","    def show_progress(a, **kwargs):\n","        return a\n","\n","tfpd = tfp.distributions\n","tfpb = tfp.bijectors\n","\n","__all__ = [\"GP\"]\n","\n","\n","def get_kernel(kernel_type, kernel_params):\n","    \"\"\"\n","    Function for producing the kernel for the Gaussian Process.\n","    Returns the selected Tinygp kernel\n","\n","    Parameters\n","    ----------\n","    kernel_type: string\n","        The type of kernel to be used for the Gaussian Process\n","        To be selected from the kernels already implemented\n","\n","    kernel_params: dict\n","        Dictionary containing the parameters for the kernel\n","        Should contain the parameters for the selected kernel\n","\n","    \"\"\"\n","    if kernel_type == \"QPO_plus_RN\":\n","        kernel = kernels.quasisep.Exp(\n","            scale=1 / kernel_params[\"crn\"], sigma=(kernel_params[\"arn\"]) ** 0.5\n","        ) + kernels.quasisep.Celerite(\n","            a=kernel_params[\"aqpo\"],\n","            b=0.0,\n","            c=kernel_params[\"cqpo\"],\n","            d=2 * jnp.pi * kernel_params[\"freq\"],\n","        )\n","        return kernel\n","    elif kernel_type == \"RN\":\n","        kernel = kernels.quasisep.Exp(\n","            scale=1 / kernel_params[\"crn\"], sigma=(kernel_params[\"arn\"]) ** 0.5\n","        )\n","        return kernel\n","\n","\n","def get_mean(mean_type, mean_params):\n","    \"\"\"\n","    Function for producing the mean for the Gaussian Process.\n","\n","    Parameters\n","    ----------\n","    mean_type: string\n","        The type of mean to be used for the Gaussian Process\n","        To be selected from the mean functions already implemented\n","\n","    mean_params: dict\n","        Dictionary containing the parameters for the mean\n","        Should contain the parameters for the selected mean\n","\n","    \"\"\"\n","    if mean_type == \"gaussian\":\n","        mean = functools.partial(_gaussian, mean_params=mean_params)\n","    elif mean_type == \"exponential\":\n","        mean = functools.partial(_exponential, mean_params=mean_params)\n","    elif mean_type == \"constant\":\n","        mean = functools.partial(_constant, mean_params=mean_params)\n","    elif mean_type == \"skew_gaussian\":\n","        mean = functools.partial(_skew_gaussian, mean_params=mean_params)\n","    elif mean_type == \"skew_exponential\":\n","        mean = functools.partial(_skew_exponential, mean_params=mean_params)\n","    elif mean_type == \"fred\":\n","        mean = functools.partial(_fred, mean_params=mean_params)\n","    return mean\n","\n","\n","def _gaussian(t, mean_params):\n","    \"\"\"A gaussian flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the gaussian.\n","\n","    Returns\n","    -------\n","    The y values for the gaussian flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig = jnp.atleast_1d(mean_params[\"sig\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(A * jnp.exp(-((t - t0) ** 2) / (2 * (sig**2))), axis=0)\n","\n","\n","def _exponential(t, mean_params):\n","    \"\"\"An exponential flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the exponential.\n","\n","    Returns\n","    -------\n","    The y values for exponential flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig = jnp.atleast_1d(mean_params[\"sig\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(A * jnp.exp(-jnp.abs(t - t0) / (2 * (sig**2))), axis=0)\n","\n","\n","def _constant(t, mean_params):\n","    \"\"\"A constant mean shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Constant amplitude of the flare.\n","\n","    Returns\n","    -------\n","    The constant value.\n","    \"\"\"\n","    return mean_params[\"A\"] * jnp.ones_like(t)\n","\n","\n","def _skew_gaussian(t, mean_params):\n","    \"\"\"A skew gaussian flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the rising edge.\n","    sig2:\n","        The width parameter for the falling edge.\n","\n","    Returns\n","    -------\n","    The y values for skew gaussian flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig1 = jnp.atleast_1d(mean_params[\"sig1\"])[:, jnp.newaxis]\n","    sig2 = jnp.atleast_1d(mean_params[\"sig2\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(\n","        A\n","        * jnp.where(\n","            t > t0,\n","            jnp.exp(-((t - t0) ** 2) / (2 * (sig2**2))),\n","            jnp.exp(-((t - t0) ** 2) / (2 * (sig1**2))),\n","        ),\n","        axis=0,\n","    )\n","\n","\n","def _skew_exponential(t, mean_params):\n","    \"\"\"A skew exponential flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the rising edge.\n","    sig2:\n","        The width parameter for the falling edge.\n","\n","    Returns\n","    -------\n","    The y values for exponential flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig1 = jnp.atleast_1d(mean_params[\"sig1\"])[:, jnp.newaxis]\n","    sig2 = jnp.atleast_1d(mean_params[\"sig2\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(\n","        A\n","        * jnp.where(\n","            t > t0,\n","            jnp.exp(-(t - t0) / (2 * (sig2**2))),\n","            jnp.exp((t - t0) / (2 * (sig1**2))),\n","        ),\n","        axis=0,\n","    )\n","\n","\n","def _fred(t, mean_params):\n","    \"\"\"A fast rise exponential decay (FRED) flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    phi:\n","        Symmetry parameter of the flare.\n","    delta:\n","        Offset parameter of the flare.\n","\n","    Returns\n","    -------\n","    The y values for exponential flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    phi = jnp.atleast_1d(mean_params[\"phi\"])[:, jnp.newaxis]\n","    delta = jnp.atleast_1d(mean_params[\"delta\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(\n","        A * jnp.exp(-phi * ((t + delta) / t0 + t0 / (t + delta))) * jnp.exp(2 * phi), axis=0\n","    )\n","\n","\n","def get_kernel_params(kernel_type):\n","    if kernel_type == \"RN\":\n","        return [\"arn\", \"crn\"]\n","    elif kernel_type == \"QPO_plus_RN\":\n","        return [\"arn\", \"crn\", \"aqpo\", \"cqpo\", \"freq\"]\n","\n","\n","def get_mean_params(mean_type):\n","    if (mean_type == \"gaussian\") or (mean_type == \"exponential\"):\n","        return [\"A\", \"t0\", \"sig\"]\n","    elif mean_type == \"constant\":\n","        return [\"A\"]\n","    elif (mean_type == \"skew_gaussian\") or (mean_type == \"skew_exponential\"):\n","        return [\"A\", \"t0\", \"sig1\", \"sig2\"]\n","    elif mean_type == \"fred\":\n","        return [\"A\", \"t0\", \"delta\", \"phi\"]\n","\n","\n","def get_gp_params(kernel_type, mean_type):\n","    kernel_params = get_kernel_params(kernel_type)\n","    mean_params = get_mean_params(mean_type)\n","    kernel_params.extend(mean_params)\n","    return kernel_params\n","\n","\n","def get_prior(params_list, prior_dict):\n","    \"\"\"\n","    A prior generator function based on given values\n","\n","    Parameters\n","    ----------\n","    params_list:\n","        A list in order of the parameters to be used.\n","\n","    prior_dict:\n","        A dictionary of the priors of parameters to be used.\n","\n","    Returns\n","    -------\n","    The Prior function.\n","    The arguments of the prior function are in the order of\n","    Kernel arguments (RN arguments, QPO arguments),\n","    Mean arguments\n","    Non Windowed arguments\n","\n","    \"\"\"\n","\n","    def prior_model():\n","        prior_list = []\n","        for i in params_list:\n","            if isinstance(prior_dict[i], tfpd.Distribution):\n","                parameter = yield Prior(prior_dict[i], name=i)\n","            else:\n","                parameter = yield prior_dict[i]\n","            prior_list.append(parameter)\n","        return tuple(prior_list)\n","\n","    return prior_model\n","\n","\n","def get_likelihood(params_list, kernel_type, mean_type, **kwargs):\n","    \"\"\"\n","    A likelihood generator function based on given values\n","\n","    Parameters\n","    ----------\n","    params_list:\n","        A list in order of the parameters to be used.\n","\n","    prior_dict:\n","        A dictionary of the priors of parameters to be used.\n","\n","    kernel_type:\n","        The type of kernel to be used in the model.\n","\n","    mean_type:\n","        The type of mean to be used in the model.\n","\n","    \"\"\"\n","\n","    @jit\n","    def likelihood_model(*args):\n","        dict = {}\n","        for i, params in enumerate(params_list):\n","            dict[params] = args[i]\n","        kernel = get_kernel(kernel_type=kernel_type, kernel_params=dict)\n","        mean = get_mean(mean_type=mean_type, mean_params=dict)\n","        gp = GaussianProcess(kernel, kwargs[\"Times\"], mean_value=mean(kwargs[\"Times\"]))\n","        return gp.log_probability(kwargs[\"counts\"])\n","\n","    return likelihood_model\n","\n","\n","class GPResult:\n","    \"\"\"\n","    Makes a GPResult object which takes in a Stingray.Lightcurve and samples parameters of a model\n","    (Gaussian Process) based on the given prior and log_likelihood function.\n","\n","    Parameters\n","    ----------\n","    lc: Stingray.Lightcurve object\n","        The lightcurve on which the bayesian inference is to be done\n","\n","    Other Parameters\n","    ----------------\n","    time : class: np.array\n","        The array containing the times of the lightcurve\n","\n","    counts : class: np.array\n","        The array containing the photon counts of the lightcurve\n","\n","    \"\"\"\n","\n","    def __init__(self, Lc: Lightcurve) -> None:\n","        self.lc = Lc\n","        self.time = Lc.time\n","        self.counts = Lc.counts\n","        self.Result = None\n","\n","    def sample(self, prior_model=None, likelihood_model=None, **kwargs):\n","        \"\"\"\n","        Makes a Jaxns nested sampler over the Gaussian Process, given the\n","        prior and likelihood model\n","\n","        Parameters\n","        ----------\n","        prior_model: jaxns.prior.PriorModelType object\n","            A prior generator object\n","\n","        likelihood_model: jaxns.types.LikelihoodType object\n","            A likelihood fucntion which takes in the arguments of the prior\n","            model and returns the loglikelihood of the model\n","\n","        Returns\n","        ----------\n","        Results: jaxns.results.NestedSamplerResults object\n","            The results of the nested sampling process\n","\n","        \"\"\"\n","\n","        if not can_sample:\n","            raise ImportError(\"Jaxns not installed! Can't sample!\")\n","\n","        self.prior_model = prior_model\n","        self.likelihood_model = likelihood_model\n","\n","        NSmodel = Model(prior_model=self.prior_model, log_likelihood=self.likelihood_model)\n","        NSmodel.sanity_check(random.PRNGKey(10), S=100)\n","\n","        self.Exact_ns = ExactNestedSampler(NSmodel, num_live_points=500, max_samples=1e4)\n","        Termination_reason, State = self.Exact_ns(\n","            random.PRNGKey(42), term_cond=TerminationCondition(live_evidence_frac=1e-4)\n","        )\n","        self.Results = self.Exact_ns.to_results(State, Termination_reason)\n","        print(\"Simulation Complete\")\n","\n","    def get_evidence(self):\n","        \"\"\"\n","        Returns the log evidence of the model\n","        \"\"\"\n","        return self.Results.log_Z_mean\n","\n","    def print_summary(self):\n","        \"\"\"\n","        Prints a summary table for the model parameters\n","        \"\"\"\n","        self.Exact_ns.summary(self.Results)\n","\n","    def plot_diagnostics(self):\n","        \"\"\"\n","        Plots the diagnostic plots for the sampling process\n","        \"\"\"\n","        self.Exact_ns.plot_diagnostics(self.Results)\n","\n","    def plot_cornerplot(self):\n","        \"\"\"\n","        Plots the corner plot for the sampled hyperparameters\n","        \"\"\"\n","        self.Exact_ns.plot_cornerplot(self.Results)\n","\n","    def get_parameters_names(self):\n","        \"\"\"\n","        Returns the names of the parameters\n","        \"\"\"\n","        return sorted(self.Results.samples.keys())\n","\n","    def get_max_posterior_parameters(self):\n","        \"\"\"\n","        Returns the optimal parameters for the model based on the NUTS sampling\n","        \"\"\"\n","        max_post_idx = jnp.argmax(self.Results.log_posterior_density)\n","        map_points = jax.tree_map(lambda x: x[max_post_idx], self.Results.samples)\n","\n","        return map_points\n","\n","    def get_max_likelihood_parameters(self):\n","        \"\"\"\n","        Retruns the maximum likelihood parameters\n","        \"\"\"\n","        max_like_idx = jnp.argmax(self.Results.log_L_samples)\n","        max_like_points = jax.tree_map(lambda x: x[max_like_idx], self.Results.samples)\n","\n","        return max_like_points\n","\n","    def posterior_plot(self, name: str, n=0):\n","        \"\"\"\n","        Plots the posterior histogram for the given parameter\n","        \"\"\"\n","        nsamples = self.Results.total_num_samples\n","        samples = self.Results.samples[name].reshape((nsamples, -1))[:, n]\n","        plt.hist(\n","            samples, bins=\"auto\", density=True, alpha=1.0, label=name, fc=\"None\", edgecolor=\"black\"\n","        )\n","        mean1 = jnp.mean(self.Results.samples[name])\n","        std1 = jnp.std(self.Results.samples[name])\n","        plt.axvline(mean1, color=\"red\", linestyle=\"dashed\", label=\"mean\")\n","        plt.axvline(mean1 + std1, color=\"green\", linestyle=\"dotted\")\n","        plt.axvline(mean1 - std1, linestyle=\"dotted\", color=\"green\")\n","        plt.legend()\n","        plt.plot()\n","\n","        pass\n","\n","    def weighted_posterior_plot(self, name: str, n=0, rkey=random.PRNGKey(1234)):\n","        \"\"\"\n","        Returns the weighted posterior histogram for the given parameter\n","        \"\"\"\n","        nsamples = self.Results.total_num_samples\n","        log_p = self.Results.log_dp_mean\n","        samples = self.Results.samples[name].reshape((nsamples, -1))[:, n]\n","\n","        weights = jnp.where(jnp.isfinite(samples), jnp.exp(log_p), 0.0)\n","        log_weights = jnp.where(jnp.isfinite(samples), log_p, -jnp.inf)\n","        samples_resampled = resample(\n","            rkey, samples, log_weights, S=max(10, int(self.Results.ESS)), replace=True\n","        )\n","\n","        nbins = max(10, int(jnp.sqrt(self.Results.ESS)) + 1)\n","        binsx = jnp.linspace(*jnp.percentile(samples_resampled, jnp.asarray([0, 100])), 2 * nbins)\n","\n","        plt.hist(\n","            np.asarray(samples_resampled),\n","            bins=binsx,\n","            density=True,\n","            alpha=1.0,\n","            label=name,\n","            fc=\"None\",\n","            edgecolor=\"black\",\n","        )\n","        sample_mean = jnp.average(samples, weights=weights)\n","        sample_std = jnp.sqrt(jnp.average((samples - sample_mean) ** 2, weights=weights))\n","        plt.axvline(sample_mean, color=\"red\", linestyle=\"dashed\", label=\"mean\")\n","        plt.axvline(sample_mean + sample_std, color=\"green\", linestyle=\"dotted\")\n","        plt.axvline(sample_mean - sample_std, linestyle=\"dotted\", color=\"green\")\n","        plt.legend()\n","        plt.plot()\n","\n","    def corner_plot(self, param1: str, param2: str, n1=0, n2=0, rkey=random.PRNGKey(1234)):\n","        \"\"\"\n","        Plots the corner plot for the given parameters\n","        \"\"\"\n","        nsamples = self.Results.total_num_samples\n","        log_p = self.Results.log_dp_mean\n","        samples1 = self.Results.samples[param1].reshape((nsamples, -1))[:, n1]\n","        samples2 = self.Results.samples[param2].reshape((nsamples, -1))[:, n2]\n","\n","        log_weights = jnp.where(jnp.isfinite(samples2), log_p, -jnp.inf)\n","        nbins = max(10, int(jnp.sqrt(self.Results.ESS)) + 1)\n","\n","        samples_resampled = resample(\n","            rkey,\n","            jnp.stack([samples1, samples2], axis=-1),\n","            log_weights,\n","            S=max(10, int(self.Results.ESS)),\n","            replace=True,\n","        )\n","        plt.hist2d(\n","            samples_resampled[:, 1],\n","            samples_resampled[:, 0],\n","            bins=(nbins, nbins),\n","            density=True,\n","            cmap=\"GnBu\",\n","        )\n","        plt.plot()\n","\n","        pass"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO[2023-07-20 01:13:09,868]: Checking if light curve is well behaved. This can take time, so if you are sure it is already sorted, specify skip_checks=True at light curve creation.\n","INFO[2023-07-20 01:13:09,869]: Checking if light curve is sorted.\n"]}],"source":["# Main GP class testing\n","\n","# Data 64 points:-\n","Times = np.linspace(0,1,64)\n","kernel_params  = {\"arn\" : jnp.exp(1.5),    \"crn\" : jnp.exp(1.0),}\n","mean_params = {\"A\" : jnp.array([3.0]), \"t0\" : jnp.array([0.2]), \"sig\" : jnp.array([0.2]) }\n","\n","kernel = get_kernel(\"RN\", kernel_params)\n","mean = get_mean(\"gaussian\", mean_params)\n","gp = GaussianProcess(kernel = kernel, X = Times, mean_value = mean(Times))\n","counts =  gp.sample(key = jax.random.PRNGKey(6))\n","\n","lc = Lightcurve(time = Times, counts = counts, dt = Times[1]- Times[0])"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["parameters list ['arn', 'crn', 'A', 't0', 'sig']\n"]}],"source":["params_list = get_gp_params(kernel_type= \"RN\", mean_type = \"gaussian\")\n","print(\"parameters list\", params_list)\n","\n","T = Times[-1] - Times[0]\n","f = 1/(Times[1]- Times[0])\n","span = jnp.max(counts) - jnp.min(counts)\n","\n","# The prior dictionary, with suitable tfpd prior distributions\n","prior_dict = {\n","    \"A\": tfpd.Uniform(low = 0.1 * span, high = 2 * span),\n","    \"t0\": tfpd.Uniform(low = Times[0] - 0.1*T, high = Times[-1] + 0.1*T),\n","    \"sig\": tfpd.Uniform(low = 0.5 * 1 / f, high = 2 * T),\n","    \"arn\": tfpd.Uniform(low = 0.1 * span, high = 2 * span),\n","    \"crn\": tfpd.Uniform(low = jnp.log(1 / T), high = jnp.log(f)),\n","}\n","\n","prior_model = get_prior(params_list, prior_dict)\n","likelihood_model = get_likelihood(params_list, kernel_type= \"RN\", mean_type = \"gaussian\", Times = Times, counts = counts)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO[2023-07-20 01:13:14,057]: Checking if light curve is well behaved. This can take time, so if you are sure it is already sorted, specify skip_checks=True at light curve creation.\n","INFO[2023-07-20 01:13:14,058]: Checking if light curve is sorted.\n","INFO[2023-07-20 01:13:14,749]: Sanity check...\n","INFO[2023-07-20 01:13:15,170]: Sanity check passed\n"]},{"name":"stdout","output_type":"stream","text":["Simulation Complete\n"]}],"source":["Gpresult = GPResult(Lightcurve(time = Times, counts = counts, dt = Times[1]- Times[0]))\n","Gpresult.sample(prior_model = prior_model, likelihood_model = likelihood_model)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO[2023-07-20 01:13:30,048]: Sanity check...\n","INFO[2023-07-20 01:13:30,053]: Sanity check passed\n"]}],"source":["NSmodel = Model(prior_model=prior_model, log_likelihood=likelihood_model)\n","NSmodel.sanity_check(random.PRNGKey(10), S=100)\n","\n","Exact_ns = ExactNestedSampler(NSmodel, num_live_points=500, max_samples=1e4)\n","Termination_reason, State = Exact_ns(\n","    random.PRNGKey(42), term_cond=TerminationCondition(live_evidence_frac=1e-4)\n",")\n","Results = Exact_ns.to_results(State, Termination_reason)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'A': Array([14.11624871, 15.60071678, 10.23459219, ...,  4.60140853,\n","        5.37371683,  5.40753515], dtype=float64), 'arn': Array([ 1.39352704,  1.03224918,  8.25467202, ..., 15.69275262,\n","       13.0247869 , 13.94319506], dtype=float64), 'crn': Array([0.10371526, 0.22498653, 0.0511483 , ..., 0.94655174, 1.13704069,\n","       1.06152496], dtype=float64), 'sig': Array([1.29221243, 1.90936547, 0.11921179, ..., 0.08344182, 0.08366165,\n","       0.08715422], dtype=float64), 't0': Array([-0.03909202,  0.82711924,  0.59833543, ...,  0.87308711,\n","        0.89011449,  0.88875816], dtype=float64)}\n"]}],"source":["print(Results.samples)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['arn', 'crn', 'A', 't0', 'sig']\n"]}],"source":["print(params_list)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["assert (Results.samples[params_list[0]]).all() == (Gpresult.Results.samples[params_list[0]]).all()\n","\n","for params in params_list:\n","    assert (Results.samples[params]).all() == (Gpresult.Results.samples[params]).all()\n","\n","assert Results.log_Z_mean == Gpresult.Results.log_Z_mean\n","\n","assert sorted(params_list) == Gpresult.get_parameters_names()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["{'A': Array(5.40753515, dtype=float64),\n"," 'arn': Array(13.94319506, dtype=float64),\n"," 'crn': Array(1.06152496, dtype=float64),\n"," 'sig': Array(0.08715422, dtype=float64),\n"," 't0': Array(0.88875816, dtype=float64)}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["Gpresult.get_max_likelihood_parameters()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["HI\n"]}],"source":["if  Results.ESS == Gpresult.Results.ESS:\n","    print(\"HI\")\n","else:\n","    print(\"Bye\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["Gpresult.get_max_likelihood_parameters()\n","for key in params_list:\n","    assert key in Gpresult.get_max_likelihood_parameters().keys()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Plotting functions testing\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
