{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Testing1"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/gaurav/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/stingray/utils.py:35: UserWarning: pyfftw not installed. Using standard scipy fft\n","  warnings.warn(\"pyfftw not installed. Using standard scipy fft\")\n","/Users/gaurav/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/stingray/utils.py:50: UserWarning: Numba not installed. Faking it\n","  warnings.warn(\"Numba not installed. Faking it\")\n","INFO[2023-07-18 16:35:22,696]: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n","INFO[2023-07-18 16:35:22,697]: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n","INFO[2023-07-18 16:35:22,699]: Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n"]}],"source":["# Required libraries\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","try:\n","    import jax\n","except ImportError:\n","    raise ImportError(\"Jax not installed\")\n","\n","import jax.numpy as jnp\n","import functools\n","import tensorflow_probability.substrates.jax as tfp\n","\n","from jax import jit, random, vmap\n","\n","from tinygp import GaussianProcess, kernels\n","from stingray import Lightcurve\n","\n","try:\n","    from jaxns import ExactNestedSampler\n","    from jaxns import TerminationCondition\n","\n","    # from jaxns import analytic_log_evidence\n","    from jaxns import Prior, Model\n","    from jaxns.utils import resample\n","    can_sample = True\n","except ImportError:\n","    can_sample = False\n","\n","\n","from jax import random\n","\n","# Have to make for all external dependencies\n","try:\n","    from tqdm import tqdm as show_progress\n","except ImportError:\n","\n","    def show_progress(a, **kwargs):\n","        return a\n","\n","jax.config.update(\"jax_enable_x64\", True)\n","\n","tfpd = tfp.distributions\n","tfpb = tfp.bijectors\n","\n","__all__ = [\"GP\"]\n","\n","\n","def get_kernel(kernel_type, kernel_params):\n","    \"\"\"\n","    Function for producing the kernel for the Gaussian Process.\n","    Returns the selected Tinygp kernel\n","\n","    Parameters\n","    ----------\n","    kernel_type: string\n","        The type of kernel to be used for the Gaussian Process\n","        To be selected from the kernels already implemented\n","\n","    kernel_params: dict\n","        Dictionary containing the parameters for the kernel\n","        Should contain the parameters for the selected kernel\n","\n","    \"\"\"\n","    if kernel_type == \"QPO_plus_RN\":\n","        kernel = kernels.quasisep.Exp(\n","            scale=1 / kernel_params[\"crn\"], sigma=(kernel_params[\"arn\"]) ** 0.5\n","        ) + kernels.quasisep.Celerite(\n","            a=kernel_params[\"aqpo\"],\n","            b=0.0,\n","            c=kernel_params[\"cqpo\"],\n","            d=2 * jnp.pi * kernel_params[\"freq\"],\n","        )\n","        return kernel\n","    elif kernel_type == \"RN\":\n","        kernel = kernels.quasisep.Exp(\n","            scale=1 / kernel_params[\"crn\"], sigma=(kernel_params[\"arn\"]) ** 0.5\n","        )\n","        return kernel\n","\n","\n","def get_mean(mean_type, mean_params):\n","    \"\"\"\n","    Function for producing the mean for the Gaussian Process.\n","\n","    Parameters\n","    ----------\n","    mean_type: string\n","        The type of mean to be used for the Gaussian Process\n","        To be selected from the mean functions already implemented\n","\n","    mean_params: dict\n","        Dictionary containing the parameters for the mean\n","        Should contain the parameters for the selected mean\n","\n","    \"\"\"\n","    if mean_type == \"gaussian\":\n","        mean = functools.partial(_gaussian, mean_params=mean_params)\n","    elif mean_type == \"exponential\":\n","        mean = functools.partial(_exponential, mean_params=mean_params)\n","    elif mean_type == \"constant\":\n","        mean = functools.partial(_constant, mean_params=mean_params)\n","    elif mean_type == \"skew_gaussian\":\n","        mean = functools.partial(_skew_gaussian, mean_params=mean_params)\n","    elif mean_type == \"skew_exponential\":\n","        mean = functools.partial(_skew_exponential, mean_params=mean_params)\n","    elif mean_type == \"fred\":\n","        mean = functools.partial(_fred, mean_params=mean_params)\n","    return mean\n","\n","\n","def _gaussian(t, mean_params):\n","    \"\"\"A gaussian flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the gaussian.\n","\n","    Returns\n","    -------\n","    The y values for the gaussian flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig = jnp.atleast_1d(mean_params[\"sig\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(A * jnp.exp(-((t - t0) ** 2) / (2 * (sig**2))), axis=0)\n","\n","\n","def _exponential(t, mean_params):\n","    \"\"\"An exponential flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the exponential.\n","\n","    Returns\n","    -------\n","    The y values for exponential flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig = jnp.atleast_1d(mean_params[\"sig\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(A * jnp.exp(-jnp.abs(t - t0) / (2 * (sig**2))), axis=0)\n","\n","\n","def _constant(t, mean_params):\n","    \"\"\"A constant mean shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Constant amplitude of the flare.\n","\n","    Returns\n","    -------\n","    The constant value.\n","    \"\"\"\n","    return mean_params[\"A\"] * jnp.ones_like(t)\n","\n","\n","def _skew_gaussian(t, mean_params):\n","    \"\"\"A skew gaussian flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the rising edge.\n","    sig2:\n","        The width parameter for the falling edge.\n","\n","    Returns\n","    -------\n","    The y values for skew gaussian flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig1 = jnp.atleast_1d(mean_params[\"sig1\"])[:, jnp.newaxis]\n","    sig2 = jnp.atleast_1d(mean_params[\"sig2\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(\n","        A\n","        * jnp.where(\n","            t > t0,\n","            jnp.exp(-((t - t0) ** 2) / (2 * (sig2**2))),\n","            jnp.exp(-((t - t0) ** 2) / (2 * (sig1**2))),\n","        ),\n","        axis=0,\n","    )\n","\n","\n","def _skew_exponential(t, mean_params):\n","    \"\"\"A skew exponential flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    sig1:\n","        The width parameter for the rising edge.\n","    sig2:\n","        The width parameter for the falling edge.\n","\n","    Returns\n","    -------\n","    The y values for exponential flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    sig1 = jnp.atleast_1d(mean_params[\"sig1\"])[:, jnp.newaxis]\n","    sig2 = jnp.atleast_1d(mean_params[\"sig2\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(\n","        A\n","        * jnp.where(\n","            t > t0,\n","            jnp.exp(-(t - t0) / (2 * (sig2**2))),\n","            jnp.exp((t - t0) / (2 * (sig1**2))),\n","        ),\n","        axis=0,\n","    )\n","\n","\n","def _fred(t, mean_params):\n","    \"\"\"A fast rise exponential decay (FRED) flare shape.\n","\n","    Parameters\n","    ----------\n","    t:  jnp.ndarray\n","        The time coordinates.\n","    A:  jnp.int\n","        Amplitude of the flare.\n","    t0:\n","        The location of the maximum.\n","    phi:\n","        Symmetry parameter of the flare.\n","    delta:\n","        Offset parameter of the flare.\n","\n","    Returns\n","    -------\n","    The y values for exponential flare.\n","    \"\"\"\n","    A = jnp.atleast_1d(mean_params[\"A\"])[:, jnp.newaxis]\n","    t0 = jnp.atleast_1d(mean_params[\"t0\"])[:, jnp.newaxis]\n","    phi = jnp.atleast_1d(mean_params[\"phi\"])[:, jnp.newaxis]\n","    delta = jnp.atleast_1d(mean_params[\"delta\"])[:, jnp.newaxis]\n","\n","    return jnp.sum(\n","        A * jnp.exp(-phi * ((t + delta) / t0 + t0 / (t + delta))) * jnp.exp(2 * phi), axis=0\n","    )\n","\n","\n","def get_kernel_params(kernel_type):\n","    if kernel_type == \"RN\":\n","        return [\"arn\", \"crn\"]\n","    elif kernel_type == \"QPO_plus_RN\":\n","        return [\"arn\", \"crn\", \"aqpo\", \"cqpo\", \"freq\"]\n","\n","\n","def get_mean_params(mean_type):\n","    if (mean_type == \"gaussian\") or (mean_type == \"exponential\"):\n","        return [\"A\", \"t0\", \"sig\"]\n","    elif mean_type == \"constant\":\n","        return [\"A\"]\n","    elif (mean_type == \"skew_gaussian\") or (mean_type == \"skew_exponential\"):\n","        return [\"A\", \"t0\", \"sig1\", \"sig2\"]\n","    elif mean_type == \"fred\":\n","        return [\"A\", \"t0\", \"delta\", \"phi\"]\n","\n","\n","def get_gp_params(kernel_type, mean_type):\n","    kernel_params = get_kernel_params(kernel_type)\n","    mean_params = get_mean_params(mean_type)\n","    kernel_params.extend(mean_params)\n","    return kernel_params\n","\n","\n","def get_prior(params_list, prior_dict):\n","    \"\"\"\n","    A prior generator function based on given values\n","\n","    Parameters\n","    ----------\n","    params_list:\n","        A list in order of the parameters to be used.\n","\n","    prior_dict:\n","        A dictionary of the priors of parameters to be used.\n","\n","    Returns\n","    -------\n","    The Prior function.\n","    The arguments of the prior function are in the order of\n","    Kernel arguments (RN arguments, QPO arguments),\n","    Mean arguments\n","    Non Windowed arguments\n","\n","    \"\"\"\n","\n","    def prior_model():\n","        prior_list = []\n","        for i in params_list:\n","            if isinstance(prior_dict[i], tfpd.Distribution):\n","                parameter = yield Prior(prior_dict[i], name=i)\n","            else:\n","                parameter = yield prior_dict[i]\n","            prior_list.append(parameter)\n","        return tuple(prior_list)\n","\n","    return prior_model\n","\n","\n","def get_likelihood(params_list, kernel_type, mean_type, **kwargs):\n","    \"\"\"\n","    A likelihood generator function based on given values\n","\n","    Parameters\n","    ----------\n","    params_list:\n","        A list in order of the parameters to be used.\n","\n","    prior_dict:\n","        A dictionary of the priors of parameters to be used.\n","\n","    kernel_type:\n","        The type of kernel to be used in the model.\n","\n","    mean_type:\n","        The type of mean to be used in the model.\n","\n","    \"\"\"\n","\n","    @jit\n","    def likelihood_model(*args):\n","        dict = {}\n","        for i, params in enumerate(params_list):\n","            dict[params] = args[i]\n","        kernel = get_kernel(kernel_type=kernel_type, kernel_params=dict)\n","        mean = get_mean(mean_type=mean_type, mean_params=dict)\n","        gp = GaussianProcess(kernel, kwargs[\"Times\"], mean_value=mean(kwargs[\"Times\"]))\n","        return gp.log_probability(kwargs[\"counts\"])\n","\n","    return likelihood_model\n","\n","\n","class GPResult:\n","    \"\"\"\n","    Makes a GPResult object which takes in a Stingray.Lightcurve and samples parameters of a model\n","    (Gaussian Process) based on the given prior and log_likelihood function.\n","\n","    Parameters\n","    ----------\n","    lc: Stingray.Lightcurve object\n","        The lightcurve on which the bayesian inference is to be done\n","\n","    Other Parameters\n","    ----------------\n","    time : class: np.array\n","        The array containing the times of the lightcurve\n","\n","    counts : class: np.array\n","        The array containing the photon counts of the lightcurve\n","\n","    \"\"\"\n","\n","    def __init__(self, Lc: Lightcurve) -> None:\n","        self.lc = Lc\n","        self.time = Lc.time\n","        self.counts = Lc.counts\n","        self.Result = None\n","\n","    def sample(self, prior_model=None, likelihood_model=None, **kwargs):\n","        \"\"\"\n","        Makes a Jaxns nested sampler over the Gaussian Process, given the\n","        prior and likelihood model\n","\n","        Parameters\n","        ----------\n","        prior_model: jaxns.prior.PriorModelType object\n","            A prior generator object\n","\n","        likelihood_model: jaxns.types.LikelihoodType object\n","            A likelihood fucntion which takes in the arguments of the prior\n","            model and returns the loglikelihood of the model\n","\n","        Returns\n","        ----------\n","        Results: jaxns.results.NestedSamplerResults object\n","            The results of the nested sampling process\n","\n","        \"\"\"\n","\n","        if not can_sample:\n","            raise ImportError(\"Jaxns not installed! Can't sample!\")\n","\n","        self.prior_model = prior_model\n","        self.likelihood_model = likelihood_model\n","\n","        NSmodel = Model(prior_model=self.prior_model, log_likelihood=self.likelihood_model)\n","        NSmodel.sanity_check(random.PRNGKey(10), S=100)\n","\n","        self.Exact_ns = ExactNestedSampler(NSmodel, num_live_points=500, max_samples=1e4)\n","        Termination_reason, State = self.Exact_ns(\n","            random.PRNGKey(42), term_cond=TerminationCondition(live_evidence_frac=1e-4)\n","        )\n","        self.Results = self.Exact_ns.to_results(State, Termination_reason)\n","        print(\"Simulation Complete\")\n","\n","    def get_evidence(self):\n","        \"\"\"\n","        Returns the log evidence of the model\n","        \"\"\"\n","        return self.Results.log_Z_mean\n","\n","    def print_summary(self):\n","        \"\"\"\n","        Prints a summary table for the model parameters\n","        \"\"\"\n","        self.Exact_ns.summary(self.Results)\n","\n","    def plot_diagnostics(self):\n","        \"\"\"\n","        Plots the diagnostic plots for the sampling process\n","        \"\"\"\n","        self.Exact_ns.plot_diagnostics(self.Results)\n","\n","    def plot_cornerplot(self):\n","        \"\"\"\n","        Plots the corner plot for the sampled hyperparameters\n","        \"\"\"\n","        self.Exact_ns.plot_cornerplot(self.Results)\n","\n","    def get_parameters_names(self):\n","        \"\"\"\n","        Returns the names of the parameters\n","        \"\"\"\n","        return sorted(self.Results.samples.keys())\n","\n","    def get_max_posterior_parameters(self):\n","        \"\"\"\n","        Returns the optimal parameters for the model based on the NUTS sampling\n","        \"\"\"\n","        max_post_idx = jnp.argmax(self.Results.log_posterior_density)\n","        map_points = jax.tree_map(lambda x: x[max_post_idx], self.Results.samples)\n","\n","        return map_points\n","\n","    def get_max_likelihood_parameters(self):\n","        \"\"\"\n","        Retruns the maximum likelihood parameters\n","        \"\"\"\n","        max_like_idx = jnp.argmax(self.Results.log_L_samples)\n","        max_like_points = jax.tree_map(lambda x: x[max_like_idx], self.Results.samples)\n","\n","        return max_like_points\n","\n","    def posterior_plot(self, name: str, n=0):\n","        \"\"\"\n","        Plots the posterior histogram for the given parameter\n","        \"\"\"\n","        nsamples = self.Results.total_num_samples\n","        samples = self.Results.samples[name].reshape((nsamples, -1))[:, n]\n","        plt.hist(\n","            samples, bins=\"auto\", density=True, alpha=1.0, label=name, fc=\"None\", edgecolor=\"black\"\n","        )\n","        mean1 = jnp.mean(self.Results.samples[name])\n","        std1 = jnp.std(self.Results.samples[name])\n","        plt.axvline(mean1, color=\"red\", linestyle=\"dashed\", label=\"mean\")\n","        plt.axvline(mean1 + std1, color=\"green\", linestyle=\"dotted\")\n","        plt.axvline(mean1 - std1, linestyle=\"dotted\", color=\"green\")\n","        plt.legend()\n","        plt.plot()\n","\n","        pass\n","\n","    def weighted_posterior_plot(self, name: str, n=0, rkey=random.PRNGKey(1234)):\n","        \"\"\"\n","        Returns the weighted posterior histogram for the given parameter\n","        \"\"\"\n","        nsamples = self.Results.total_num_samples\n","        log_p = self.Results.log_dp_mean\n","        samples = self.Results.samples[name].reshape((nsamples, -1))[:, n]\n","\n","        weights = jnp.where(jnp.isfinite(samples), jnp.exp(log_p), 0.0)\n","        log_weights = jnp.where(jnp.isfinite(samples), log_p, -jnp.inf)\n","        samples_resampled = resample(\n","            rkey, samples, log_weights, S=max(10, int(self.Results.ESS)), replace=True\n","        )\n","\n","        nbins = max(10, int(jnp.sqrt(self.Results.ESS)) + 1)\n","        binsx = jnp.linspace(*jnp.percentile(samples_resampled, jnp.asarray([0, 100])), 2 * nbins)\n","\n","        plt.hist(\n","            np.asarray(samples_resampled),\n","            bins=binsx,\n","            density=True,\n","            alpha=1.0,\n","            label=name,\n","            fc=\"None\",\n","            edgecolor=\"black\",\n","        )\n","        sample_mean = jnp.average(samples, weights=weights)\n","        sample_std = jnp.sqrt(jnp.average((samples - sample_mean) ** 2, weights=weights))\n","        plt.axvline(sample_mean, color=\"red\", linestyle=\"dashed\", label=\"mean\")\n","        plt.axvline(sample_mean + sample_std, color=\"green\", linestyle=\"dotted\")\n","        plt.axvline(sample_mean - sample_std, linestyle=\"dotted\", color=\"green\")\n","        plt.legend()\n","        plt.plot()\n","\n","    def corner_plot(self, param1: str, param2: str, n1=0, n2=0, rkey=random.PRNGKey(1234)):\n","        \"\"\"\n","        Plots the corner plot for the given parameters\n","        \"\"\"\n","        nsamples = self.Results.total_num_samples\n","        log_p = self.Results.log_dp_mean\n","        samples1 = self.Results.samples[param1].reshape((nsamples, -1))[:, n1]\n","        samples2 = self.Results.samples[param2].reshape((nsamples, -1))[:, n2]\n","\n","        log_weights = jnp.where(jnp.isfinite(samples2), log_p, -jnp.inf)\n","        nbins = max(10, int(jnp.sqrt(self.Results.ESS)) + 1)\n","\n","        samples_resampled = resample(\n","            rkey,\n","            jnp.stack([samples1, samples2], axis=-1),\n","            log_weights,\n","            S=max(10, int(self.Results.ESS)),\n","            replace=True,\n","        )\n","        plt.hist2d(\n","            samples_resampled[:, 1],\n","            samples_resampled[:, 0],\n","            bins=(nbins, nbins),\n","            density=True,\n","            cmap=\"GnBu\",\n","        )\n","        plt.plot()\n","\n","        pass"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO[2023-07-18 16:35:41,742]: Checking if light curve is well behaved. This can take time, so if you are sure it is already sorted, specify skip_checks=True at light curve creation.\n","INFO[2023-07-18 16:35:41,743]: Checking if light curve is sorted.\n"]}],"source":["# Main GP class testing\n","\n","# Data 64 points:-\n","Times = np.linspace(0,1,128)\n","kernel_params  = {\"arn\" : jnp.exp(1.5),    \"crn\" : jnp.exp(1.0),}\n","mean_params = {\"A\" : jnp.array([3.0]), \"t0\" : jnp.array([0.2]), \"sig\" : jnp.array([0.2]) }\n","\n","kernel = get_kernel(\"RN\", kernel_params)\n","mean = get_mean(\"gaussian\", mean_params)\n","gp = GaussianProcess(kernel = kernel, X = Times, mean_value = mean(Times))\n","counts =  gp.sample(key = jax.random.PRNGKey(6))\n","\n","# fig, ax = plt.subplots(1,1, figsize = (14,6))\n","# ax.plot(Times, counts.T, label=\"data\")\n","# ax.plot(Times, mean(Times), color = \"orange\" ,label = \"Mean\"); ax.legend()\n","\n","# Lightcurve only takes np arrays not jnp arrays\n","lc = Lightcurve(time = Times, counts = counts, dt = Times[1]- Times[0])\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["parameters list ['arn', 'crn', 'A', 't0', 'sig']\n"]}],"source":["params_list = get_gp_params(kernel_type= \"RN\", mean_type = \"gaussian\")\n","print(\"parameters list\", params_list)\n","\n","T = Times[-1] - Times[0]\n","f = 1/(Times[1]- Times[0])\n","span = jnp.max(counts) - jnp.min(counts)\n","\n","# The prior dictionary, with suitable tfpd prior distributions\n","prior_dict = {\n","    \"A\": tfpd.Uniform(low = 0.1 * span, high = 2 * span),\n","    \"t0\": tfpd.Uniform(low = Times[0] - 0.1*T, high = Times[-1] + 0.1*T),\n","    \"sig\": tfpd.Uniform(low = 0.5 * 1 / f, high = 2 * T),\n","    \"arn\": tfpd.Uniform(low = 0.1 * span, high = 2 * span),\n","    \"crn\": tfpd.Uniform(low = jnp.log(1 / T), high = jnp.log(f)),\n","}\n","\n","prior_model = get_prior(params_list, prior_dict)\n","likelihood_model = get_likelihood(params_list, kernel_type= \"RN\", mean_type = \"gaussian\", Times = Times, counts = counts)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO[2023-07-18 16:38:09,769]: Sanity check...\n","INFO[2023-07-18 16:38:09,774]: Sanity check passed\n"]},{"ename":"TypeError","evalue":"body_fun output and input must have identical types, got\n(UniDimProposalState(key='ShapedArray(uint32[2])', process_step='ShapedArray(int32[])', proposal_count='ShapedArray(int32[])', num_likelihood_evaluations='ShapedArray(int32[])', point_U0='ShapedArray(float32[5])', log_L0='ShapedArray(float32[])', direction='ShapedArray(float32[5])', left='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', right='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', point_U='ShapedArray(float32[5])', t='ShapedArray(float32[])', log_L_constraint='ShapedArray(float32[])'), 'ShapedArray(float32[])').","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m NSmodel\u001b[39m.\u001b[39msanity_check(random\u001b[39m.\u001b[39mPRNGKey(\u001b[39m10\u001b[39m), S\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      4\u001b[0m Exact_ns \u001b[39m=\u001b[39m ExactNestedSampler(NSmodel, num_live_points\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, max_samples\u001b[39m=\u001b[39m\u001b[39m1e4\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m Termination_reason, State \u001b[39m=\u001b[39m Exact_ns(\n\u001b[1;32m      6\u001b[0m             random\u001b[39m.\u001b[39;49mPRNGKey(\u001b[39m42\u001b[39;49m), term_cond\u001b[39m=\u001b[39;49mTerminationCondition(live_evidence_frac\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m))\n\u001b[1;32m      7\u001b[0m Results \u001b[39m=\u001b[39m Exact_ns\u001b[39m.\u001b[39mto_results(State, Termination_reason)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSimulation Complete\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:407\u001b[0m, in \u001b[0;36mExactNestedSampler.__call__\u001b[0;34m(self, key, term_cond, init_state)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, core\u001b[39m.\u001b[39mTracer):\n\u001b[1;32m    405\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTracer detected, but expected imperative context.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m termination_reason, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate_sampler(key\u001b[39m=\u001b[39;49mkey, term_cond\u001b[39m=\u001b[39;49mterm_cond, init_state\u001b[39m=\u001b[39;49minit_state)\n\u001b[1;32m    408\u001b[0m \u001b[39m# TODO: Turn on adaptive refinement after fixing bias issue\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[39m# Note: for now exact here means that we ensure i.i.d. samples by choosing strong hyper parameters for samplers.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39m# state = self.adaptive_refinement(state=state)\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mreturn\u001b[39;00m termination_reason, state\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:340\u001b[0m, in \u001b[0;36mApproximateNestedSampler.__call__\u001b[0;34m(self, key, term_cond, init_state)\u001b[0m\n\u001b[1;32m    337\u001b[0m     term_cond \u001b[39m=\u001b[39m term_cond\u001b[39m.\u001b[39m_replace(max_samples\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mminimum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_samples, term_cond\u001b[39m.\u001b[39mmax_samples))\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m init_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     \u001b[39m# We create fresh live points and state\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     termination_reason, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfresh_run(key\u001b[39m=\u001b[39;49mkey, term_cond\u001b[39m=\u001b[39;49mterm_cond)\n\u001b[1;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[39m# We use the input live points and run on top of init_state\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     init_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize_state(init_state, max_num_samples\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_samples)\n","    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:279\u001b[0m, in \u001b[0;36mApproximateNestedSampler.fresh_run\u001b[0;34m(self, key, term_cond)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39mCreates a new initial state and live points from -inf contour and samples until termination.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    termination reason, and state\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m state, live_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise(key\u001b[39m=\u001b[39mkey, num_live_points\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_live_points)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate_shrinkage(state\u001b[39m=\u001b[39;49mstate, live_points\u001b[39m=\u001b[39;49mlive_points, term_cond\u001b[39m=\u001b[39;49mterm_cond)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:261\u001b[0m, in \u001b[0;36mApproximateNestedSampler.approximate_shrinkage\u001b[0;34m(self, state, live_points, term_cond)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapproximate_shrinkage\u001b[39m(\u001b[39mself\u001b[39m, state: NestedSamplerState, live_points: LivePoints,\n\u001b[1;32m    247\u001b[0m                           term_cond: TerminationCondition) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[IntArray, NestedSamplerState]:\n\u001b[1;32m    248\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m    Performs approximate shrinkage using a fast but inaccurate static nested sampler.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m        termination reason, and state\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     termination_reason, state, live_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nested_sampler(\n\u001b[1;32m    262\u001b[0m         state\u001b[39m=\u001b[39;49mstate, live_points\u001b[39m=\u001b[39;49mlive_points, termination_cond\u001b[39m=\u001b[39;49mterm_cond)\n\u001b[1;32m    263\u001b[0m     state \u001b[39m=\u001b[39m collect_samples(state\u001b[39m=\u001b[39mstate, new_reservoir\u001b[39m=\u001b[39mlive_points\u001b[39m.\u001b[39mreservoir)\n\u001b[1;32m    264\u001b[0m     \u001b[39mreturn\u001b[39;00m termination_reason, state\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:372\u001b[0m, in \u001b[0;36mStaticNestedSampler.__call__\u001b[0;34m(self, state, live_points, termination_cond)\u001b[0m\n\u001b[1;32m    363\u001b[0m keys \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(state\u001b[39m.\u001b[39mkey, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samplers)\n\u001b[1;32m    365\u001b[0m parallel_ns \u001b[39m=\u001b[39m pmap(\u001b[39mlambda\u001b[39;00m key, live_points: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_thread_ns(\n\u001b[1;32m    366\u001b[0m     key\u001b[39m=\u001b[39mkey,\n\u001b[1;32m    367\u001b[0m     state\u001b[39m=\u001b[39mstate,\n\u001b[1;32m    368\u001b[0m     live_points\u001b[39m=\u001b[39mlive_points,\n\u001b[1;32m    369\u001b[0m     termination_cond\u001b[39m=\u001b[39mtermination_cond\n\u001b[1;32m    370\u001b[0m ), axis_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 372\u001b[0m chunked_termination_reason, chunked_state, chunked_live_points \u001b[39m=\u001b[39m parallel_ns(keys, chunked_live_points)\n\u001b[1;32m    374\u001b[0m termination_reason, state \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m], (chunked_termination_reason, chunked_state))\n\u001b[1;32m    375\u001b[0m live_points \u001b[39m=\u001b[39m remove_chunk_dim(chunked_live_points)\n","    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:365\u001b[0m, in \u001b[0;36mStaticNestedSampler.__call__.<locals>.<lambda>\u001b[0;34m(key, live_points)\u001b[0m\n\u001b[1;32m    361\u001b[0m chunked_live_points \u001b[39m=\u001b[39m add_chunk_dim(live_points, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samplers)\n\u001b[1;32m    363\u001b[0m keys \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(state\u001b[39m.\u001b[39mkey, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samplers)\n\u001b[0;32m--> 365\u001b[0m parallel_ns \u001b[39m=\u001b[39m pmap(\u001b[39mlambda\u001b[39;00m key, live_points: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_thread_ns(\n\u001b[1;32m    366\u001b[0m     key\u001b[39m=\u001b[39;49mkey,\n\u001b[1;32m    367\u001b[0m     state\u001b[39m=\u001b[39;49mstate,\n\u001b[1;32m    368\u001b[0m     live_points\u001b[39m=\u001b[39;49mlive_points,\n\u001b[1;32m    369\u001b[0m     termination_cond\u001b[39m=\u001b[39;49mtermination_cond\n\u001b[1;32m    370\u001b[0m ), axis_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    372\u001b[0m chunked_termination_reason, chunked_state, chunked_live_points \u001b[39m=\u001b[39m parallel_ns(keys, chunked_live_points)\n\u001b[1;32m    374\u001b[0m termination_reason, state \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m], (chunked_termination_reason, chunked_state))\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:345\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_thread_ns\u001b[0;34m(self, key, state, live_points, termination_cond)\u001b[0m\n\u001b[1;32m    335\u001b[0m     done, termination_reason \u001b[39m=\u001b[39m stopping_cond(\n\u001b[1;32m    336\u001b[0m         state\u001b[39m=\u001b[39mcarry_state\u001b[39m.\u001b[39mstate,\n\u001b[1;32m    337\u001b[0m         live_points\u001b[39m=\u001b[39mcarry_state\u001b[39m.\u001b[39mlive_points,\n\u001b[1;32m    338\u001b[0m         term_cond\u001b[39m=\u001b[39mterm_cond\n\u001b[1;32m    339\u001b[0m     )\n\u001b[1;32m    341\u001b[0m     carry_state \u001b[39m=\u001b[39m carry_state\u001b[39m.\u001b[39m_replace(\n\u001b[1;32m    342\u001b[0m         done\u001b[39m=\u001b[39mdone\n\u001b[1;32m    343\u001b[0m     )\n\u001b[0;32m--> 345\u001b[0m     carry_state \u001b[39m=\u001b[39m while_loop(\n\u001b[1;32m    346\u001b[0m         \u001b[39mlambda\u001b[39;49;00m body_state: jnp\u001b[39m.\u001b[39;49mbitwise_not(body_state\u001b[39m.\u001b[39;49mdone),\n\u001b[1;32m    347\u001b[0m         build_body(sampler\u001b[39m=\u001b[39;49msampler, term_cond\u001b[39m=\u001b[39;49mterm_cond),\n\u001b[1;32m    348\u001b[0m         carry_state\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m carry_state\u001b[39m.\u001b[39mtermination_reason, carry_state\u001b[39m.\u001b[39mstate, carry_state\u001b[39m.\u001b[39mlive_points\n","    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:304\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_thread_ns.<locals>.build_body.<locals>.body\u001b[0;34m(body_state)\u001b[0m\n\u001b[1;32m    300\u001b[0m state \u001b[39m=\u001b[39m body_state\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39m_replace(key\u001b[39m=\u001b[39mkey)\n\u001b[1;32m    302\u001b[0m preprocess_data \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39mpreprocess(state\u001b[39m=\u001b[39mstate, live_points\u001b[39m=\u001b[39mbody_state\u001b[39m.\u001b[39mlive_points)\n\u001b[0;32m--> 304\u001b[0m (dead_reservoir, live_points, log_L_contour) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_live_point_shrink(\n\u001b[1;32m    305\u001b[0m     key\u001b[39m=\u001b[39;49msample_key,\n\u001b[1;32m    306\u001b[0m     live_points\u001b[39m=\u001b[39;49mbody_state\u001b[39m.\u001b[39;49mlive_points,\n\u001b[1;32m    307\u001b[0m     log_L_contour\u001b[39m=\u001b[39;49mbody_state\u001b[39m.\u001b[39;49mlog_L_contour,\n\u001b[1;32m    308\u001b[0m     preprocess_data\u001b[39m=\u001b[39;49mpreprocess_data,\n\u001b[1;32m    309\u001b[0m     sampler\u001b[39m=\u001b[39;49msampler\n\u001b[1;32m    310\u001b[0m )\n\u001b[1;32m    311\u001b[0m \u001b[39m# Collect dead reservoirs from all devices, and merge into state\u001b[39;00m\n\u001b[1;32m    312\u001b[0m all_dead_reservoir: Reservoir \u001b[39m=\u001b[39m remove_chunk_dim(all_gather(dead_reservoir, \u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m))\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:252\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_live_point_shrink\u001b[0;34m(self, key, live_points, log_L_contour, preprocess_data, sampler)\u001b[0m\n\u001b[1;32m    250\u001b[0m init_carry \u001b[39m=\u001b[39m CarryType(key\u001b[39m=\u001b[39mkey, live_points\u001b[39m=\u001b[39mlive_points, log_L_contour\u001b[39m=\u001b[39mlog_L_contour)\n\u001b[1;32m    251\u001b[0m init_X \u001b[39m=\u001b[39m live_points\u001b[39m.\u001b[39mreservoir\u001b[39m.\u001b[39mlog_L\n\u001b[0;32m--> 252\u001b[0m (_, live_points, log_L_contour), dead_reservoir \u001b[39m=\u001b[39m scan(body, init_carry, init_X)\n\u001b[1;32m    253\u001b[0m \u001b[39mreturn\u001b[39;00m (dead_reservoir, live_points, log_L_contour)\n","    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:239\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_live_point_shrink.<locals>.body\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m# replace dead point with a new sample about contour\u001b[39;00m\n\u001b[1;32m    237\u001b[0m key, sample_key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(carry\u001b[39m.\u001b[39mkey, \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 239\u001b[0m sample \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49mget_sample(key\u001b[39m=\u001b[39;49msample_key,\n\u001b[1;32m    240\u001b[0m                             log_L_constraint\u001b[39m=\u001b[39;49mlog_L_contour,\n\u001b[1;32m    241\u001b[0m                             live_points\u001b[39m=\u001b[39;49mcarry\u001b[39m.\u001b[39;49mlive_points,\n\u001b[1;32m    242\u001b[0m                             preprocess_data\u001b[39m=\u001b[39;49mpreprocess_data)\n\u001b[1;32m    244\u001b[0m live_points_reservoir \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m old, update: old\u001b[39m.\u001b[39mat[idx_min]\u001b[39m.\u001b[39mset(update),\n\u001b[1;32m    245\u001b[0m                                  carry\u001b[39m.\u001b[39mlive_points\u001b[39m.\u001b[39mreservoir, Reservoir(\u001b[39m*\u001b[39msample))\n\u001b[1;32m    246\u001b[0m live_points \u001b[39m=\u001b[39m carry\u001b[39m.\u001b[39mlive_points\u001b[39m.\u001b[39m_replace(reservoir\u001b[39m=\u001b[39mlive_points_reservoir)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:155\u001b[0m, in \u001b[0;36mMarkovSampler.get_sample\u001b[0;34m(self, key, log_L_constraint, live_points, preprocess_data)\u001b[0m\n\u001b[1;32m    153\u001b[0m key, seed_key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(key, \u001b[39m2\u001b[39m)\n\u001b[1;32m    154\u001b[0m seed_point \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_seed_point(key\u001b[39m=\u001b[39mseed_key, live_points\u001b[39m=\u001b[39mlive_points, log_L_constraint\u001b[39m=\u001b[39mlog_L_constraint)\n\u001b[0;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_sample_from_seed(key\u001b[39m=\u001b[39;49mkey, seed_point\u001b[39m=\u001b[39;49mseed_point, log_L_constraint\u001b[39m=\u001b[39;49mlog_L_constraint,\n\u001b[1;32m    156\u001b[0m                                  preprocess_data\u001b[39m=\u001b[39;49mpreprocess_data)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/slice_samplers.py:302\u001b[0m, in \u001b[0;36mUniDimSliceSampler.get_sample_from_seed\u001b[0;34m(self, key, seed_point, log_L_constraint, preprocess_data)\u001b[0m\n\u001b[1;32m    299\u001b[0m     (proposal_state, _) \u001b[39m=\u001b[39m body_state\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mless(proposal_state\u001b[39m.\u001b[39mproposal_count, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_slices)\n\u001b[0;32m--> 302\u001b[0m (proposal_state, log_L) \u001b[39m=\u001b[39m while_loop(slice_sampler_cond,\n\u001b[1;32m    303\u001b[0m                                      slice_sampler_body,\n\u001b[1;32m    304\u001b[0m                                      (init_proposal_state, \u001b[39m-\u001b[39;49mjnp\u001b[39m.\u001b[39;49minf))\n\u001b[1;32m    305\u001b[0m \u001b[39m# when num_slices==0, that means we don't want to run this\u001b[39;00m\n\u001b[1;32m    306\u001b[0m pass_through \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_slices \u001b[39m==\u001b[39m jnp\u001b[39m.\u001b[39mzeros_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_slices)\n","    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jax/_src/lax/control_flow/common.py:202\u001b[0m, in \u001b[0;36m_check_tree_and_avals\u001b[0;34m(what, tree1, avals1, tree2, avals2)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mmap\u001b[39m(core\u001b[39m.\u001b[39mtypematch, avals1, avals2)):\n\u001b[1;32m    200\u001b[0m   diff \u001b[39m=\u001b[39m tree_map(_show_diff, tree_unflatten(tree1, avals1),\n\u001b[1;32m    201\u001b[0m                   tree_unflatten(tree2, avals2))\n\u001b[0;32m--> 202\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mwhat\u001b[39m}\u001b[39;00m\u001b[39m must have identical types, got\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiff\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: body_fun output and input must have identical types, got\n(UniDimProposalState(key='ShapedArray(uint32[2])', process_step='ShapedArray(int32[])', proposal_count='ShapedArray(int32[])', num_likelihood_evaluations='ShapedArray(int32[])', point_U0='ShapedArray(float32[5])', log_L0='ShapedArray(float32[])', direction='ShapedArray(float32[5])', left='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', right='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', point_U='ShapedArray(float32[5])', t='ShapedArray(float32[])', log_L_constraint='ShapedArray(float32[])'), 'ShapedArray(float32[])')."]}],"source":["NSmodel = Model(prior_model=prior_model, log_likelihood=likelihood_model)\n","NSmodel.sanity_check(random.PRNGKey(10), S=100)\n","\n","Exact_ns = ExactNestedSampler(NSmodel, num_live_points=500, max_samples=1e4)\n","Termination_reason, State = Exact_ns(\n","            random.PRNGKey(42), term_cond=TerminationCondition(live_evidence_frac=1e-3))\n","Results = Exact_ns.to_results(State, Termination_reason)\n","print(\"Simulation Complete\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO[2023-07-18 16:35:45,143]: Checking if light curve is well behaved. This can take time, so if you are sure it is already sorted, specify skip_checks=True at light curve creation.\n","INFO[2023-07-18 16:35:45,145]: Checking if light curve is sorted.\n","INFO[2023-07-18 16:35:45,706]: Sanity check...\n","INFO[2023-07-18 16:35:45,711]: Sanity check passed\n","/Users/gaurav/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=float64. In future JAX releases this will result in an error.\n","  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n"]},{"ename":"TypeError","evalue":"body_fun output and input must have identical types, got\n(UniDimProposalState(key='ShapedArray(uint32[2])', process_step='ShapedArray(int32[])', proposal_count='ShapedArray(int32[])', num_likelihood_evaluations='ShapedArray(int32[])', point_U0='ShapedArray(float32[5])', log_L0='ShapedArray(float32[])', direction='ShapedArray(float32[5])', left='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', right='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', point_U='ShapedArray(float32[5])', t='ShapedArray(float32[])', log_L_constraint='ShapedArray(float32[])'), 'ShapedArray(float32[])').","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Gpresult \u001b[39m=\u001b[39m GPResult(Lightcurve(time \u001b[39m=\u001b[39m Times, counts \u001b[39m=\u001b[39m counts, dt \u001b[39m=\u001b[39m Times[\u001b[39m1\u001b[39m]\u001b[39m-\u001b[39m Times[\u001b[39m0\u001b[39m]))\n\u001b[0;32m----> 2\u001b[0m Gpresult\u001b[39m.\u001b[39;49msample(prior_model \u001b[39m=\u001b[39;49m prior_model, likelihood_model \u001b[39m=\u001b[39;49m likelihood_model)\n","Cell \u001b[0;32mIn[1], line 431\u001b[0m, in \u001b[0;36mGPResult.sample\u001b[0;34m(self, prior_model, likelihood_model, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m NSmodel\u001b[39m.\u001b[39msanity_check(random\u001b[39m.\u001b[39mPRNGKey(\u001b[39m10\u001b[39m), S\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m    430\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mExact_ns \u001b[39m=\u001b[39m ExactNestedSampler(NSmodel, num_live_points\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, max_samples\u001b[39m=\u001b[39m\u001b[39m1e4\u001b[39m)\n\u001b[0;32m--> 431\u001b[0m Termination_reason, State \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mExact_ns(\n\u001b[1;32m    432\u001b[0m     random\u001b[39m.\u001b[39;49mPRNGKey(\u001b[39m42\u001b[39;49m), term_cond\u001b[39m=\u001b[39;49mTerminationCondition(live_evidence_frac\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m)\n\u001b[1;32m    433\u001b[0m )\n\u001b[1;32m    434\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mResults \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mExact_ns\u001b[39m.\u001b[39mto_results(State, Termination_reason)\n\u001b[1;32m    435\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSimulation Complete\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:407\u001b[0m, in \u001b[0;36mExactNestedSampler.__call__\u001b[0;34m(self, key, term_cond, init_state)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, core\u001b[39m.\u001b[39mTracer):\n\u001b[1;32m    405\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTracer detected, but expected imperative context.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m termination_reason, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate_sampler(key\u001b[39m=\u001b[39;49mkey, term_cond\u001b[39m=\u001b[39;49mterm_cond, init_state\u001b[39m=\u001b[39;49minit_state)\n\u001b[1;32m    408\u001b[0m \u001b[39m# TODO: Turn on adaptive refinement after fixing bias issue\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[39m# Note: for now exact here means that we ensure i.i.d. samples by choosing strong hyper parameters for samplers.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39m# state = self.adaptive_refinement(state=state)\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mreturn\u001b[39;00m termination_reason, state\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:340\u001b[0m, in \u001b[0;36mApproximateNestedSampler.__call__\u001b[0;34m(self, key, term_cond, init_state)\u001b[0m\n\u001b[1;32m    337\u001b[0m     term_cond \u001b[39m=\u001b[39m term_cond\u001b[39m.\u001b[39m_replace(max_samples\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mminimum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_samples, term_cond\u001b[39m.\u001b[39mmax_samples))\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m init_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     \u001b[39m# We create fresh live points and state\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m     termination_reason, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfresh_run(key\u001b[39m=\u001b[39;49mkey, term_cond\u001b[39m=\u001b[39;49mterm_cond)\n\u001b[1;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[39m# We use the input live points and run on top of init_state\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     init_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize_state(init_state, max_num_samples\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_samples)\n","    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:279\u001b[0m, in \u001b[0;36mApproximateNestedSampler.fresh_run\u001b[0;34m(self, key, term_cond)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39mCreates a new initial state and live points from -inf contour and samples until termination.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    termination reason, and state\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m state, live_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise(key\u001b[39m=\u001b[39mkey, num_live_points\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_live_points)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate_shrinkage(state\u001b[39m=\u001b[39;49mstate, live_points\u001b[39m=\u001b[39;49mlive_points, term_cond\u001b[39m=\u001b[39;49mterm_cond)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/nested_sampler.py:261\u001b[0m, in \u001b[0;36mApproximateNestedSampler.approximate_shrinkage\u001b[0;34m(self, state, live_points, term_cond)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapproximate_shrinkage\u001b[39m(\u001b[39mself\u001b[39m, state: NestedSamplerState, live_points: LivePoints,\n\u001b[1;32m    247\u001b[0m                           term_cond: TerminationCondition) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[IntArray, NestedSamplerState]:\n\u001b[1;32m    248\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m    Performs approximate shrinkage using a fast but inaccurate static nested sampler.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m        termination reason, and state\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     termination_reason, state, live_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nested_sampler(\n\u001b[1;32m    262\u001b[0m         state\u001b[39m=\u001b[39;49mstate, live_points\u001b[39m=\u001b[39;49mlive_points, termination_cond\u001b[39m=\u001b[39;49mterm_cond)\n\u001b[1;32m    263\u001b[0m     state \u001b[39m=\u001b[39m collect_samples(state\u001b[39m=\u001b[39mstate, new_reservoir\u001b[39m=\u001b[39mlive_points\u001b[39m.\u001b[39mreservoir)\n\u001b[1;32m    264\u001b[0m     \u001b[39mreturn\u001b[39;00m termination_reason, state\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:372\u001b[0m, in \u001b[0;36mStaticNestedSampler.__call__\u001b[0;34m(self, state, live_points, termination_cond)\u001b[0m\n\u001b[1;32m    363\u001b[0m keys \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(state\u001b[39m.\u001b[39mkey, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samplers)\n\u001b[1;32m    365\u001b[0m parallel_ns \u001b[39m=\u001b[39m pmap(\u001b[39mlambda\u001b[39;00m key, live_points: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_thread_ns(\n\u001b[1;32m    366\u001b[0m     key\u001b[39m=\u001b[39mkey,\n\u001b[1;32m    367\u001b[0m     state\u001b[39m=\u001b[39mstate,\n\u001b[1;32m    368\u001b[0m     live_points\u001b[39m=\u001b[39mlive_points,\n\u001b[1;32m    369\u001b[0m     termination_cond\u001b[39m=\u001b[39mtermination_cond\n\u001b[1;32m    370\u001b[0m ), axis_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 372\u001b[0m chunked_termination_reason, chunked_state, chunked_live_points \u001b[39m=\u001b[39m parallel_ns(keys, chunked_live_points)\n\u001b[1;32m    374\u001b[0m termination_reason, state \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m], (chunked_termination_reason, chunked_state))\n\u001b[1;32m    375\u001b[0m live_points \u001b[39m=\u001b[39m remove_chunk_dim(chunked_live_points)\n","    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:365\u001b[0m, in \u001b[0;36mStaticNestedSampler.__call__.<locals>.<lambda>\u001b[0;34m(key, live_points)\u001b[0m\n\u001b[1;32m    361\u001b[0m chunked_live_points \u001b[39m=\u001b[39m add_chunk_dim(live_points, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samplers)\n\u001b[1;32m    363\u001b[0m keys \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(state\u001b[39m.\u001b[39mkey, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samplers)\n\u001b[0;32m--> 365\u001b[0m parallel_ns \u001b[39m=\u001b[39m pmap(\u001b[39mlambda\u001b[39;00m key, live_points: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_thread_ns(\n\u001b[1;32m    366\u001b[0m     key\u001b[39m=\u001b[39;49mkey,\n\u001b[1;32m    367\u001b[0m     state\u001b[39m=\u001b[39;49mstate,\n\u001b[1;32m    368\u001b[0m     live_points\u001b[39m=\u001b[39;49mlive_points,\n\u001b[1;32m    369\u001b[0m     termination_cond\u001b[39m=\u001b[39;49mtermination_cond\n\u001b[1;32m    370\u001b[0m ), axis_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    372\u001b[0m chunked_termination_reason, chunked_state, chunked_live_points \u001b[39m=\u001b[39m parallel_ns(keys, chunked_live_points)\n\u001b[1;32m    374\u001b[0m termination_reason, state \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m], (chunked_termination_reason, chunked_state))\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:345\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_thread_ns\u001b[0;34m(self, key, state, live_points, termination_cond)\u001b[0m\n\u001b[1;32m    335\u001b[0m     done, termination_reason \u001b[39m=\u001b[39m stopping_cond(\n\u001b[1;32m    336\u001b[0m         state\u001b[39m=\u001b[39mcarry_state\u001b[39m.\u001b[39mstate,\n\u001b[1;32m    337\u001b[0m         live_points\u001b[39m=\u001b[39mcarry_state\u001b[39m.\u001b[39mlive_points,\n\u001b[1;32m    338\u001b[0m         term_cond\u001b[39m=\u001b[39mterm_cond\n\u001b[1;32m    339\u001b[0m     )\n\u001b[1;32m    341\u001b[0m     carry_state \u001b[39m=\u001b[39m carry_state\u001b[39m.\u001b[39m_replace(\n\u001b[1;32m    342\u001b[0m         done\u001b[39m=\u001b[39mdone\n\u001b[1;32m    343\u001b[0m     )\n\u001b[0;32m--> 345\u001b[0m     carry_state \u001b[39m=\u001b[39m while_loop(\n\u001b[1;32m    346\u001b[0m         \u001b[39mlambda\u001b[39;49;00m body_state: jnp\u001b[39m.\u001b[39;49mbitwise_not(body_state\u001b[39m.\u001b[39;49mdone),\n\u001b[1;32m    347\u001b[0m         build_body(sampler\u001b[39m=\u001b[39;49msampler, term_cond\u001b[39m=\u001b[39;49mterm_cond),\n\u001b[1;32m    348\u001b[0m         carry_state\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m carry_state\u001b[39m.\u001b[39mtermination_reason, carry_state\u001b[39m.\u001b[39mstate, carry_state\u001b[39m.\u001b[39mlive_points\n","    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:304\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_thread_ns.<locals>.build_body.<locals>.body\u001b[0;34m(body_state)\u001b[0m\n\u001b[1;32m    300\u001b[0m state \u001b[39m=\u001b[39m body_state\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39m_replace(key\u001b[39m=\u001b[39mkey)\n\u001b[1;32m    302\u001b[0m preprocess_data \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39mpreprocess(state\u001b[39m=\u001b[39mstate, live_points\u001b[39m=\u001b[39mbody_state\u001b[39m.\u001b[39mlive_points)\n\u001b[0;32m--> 304\u001b[0m (dead_reservoir, live_points, log_L_contour) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_live_point_shrink(\n\u001b[1;32m    305\u001b[0m     key\u001b[39m=\u001b[39;49msample_key,\n\u001b[1;32m    306\u001b[0m     live_points\u001b[39m=\u001b[39;49mbody_state\u001b[39m.\u001b[39;49mlive_points,\n\u001b[1;32m    307\u001b[0m     log_L_contour\u001b[39m=\u001b[39;49mbody_state\u001b[39m.\u001b[39;49mlog_L_contour,\n\u001b[1;32m    308\u001b[0m     preprocess_data\u001b[39m=\u001b[39;49mpreprocess_data,\n\u001b[1;32m    309\u001b[0m     sampler\u001b[39m=\u001b[39;49msampler\n\u001b[1;32m    310\u001b[0m )\n\u001b[1;32m    311\u001b[0m \u001b[39m# Collect dead reservoirs from all devices, and merge into state\u001b[39;00m\n\u001b[1;32m    312\u001b[0m all_dead_reservoir: Reservoir \u001b[39m=\u001b[39m remove_chunk_dim(all_gather(dead_reservoir, \u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m))\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:252\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_live_point_shrink\u001b[0;34m(self, key, live_points, log_L_contour, preprocess_data, sampler)\u001b[0m\n\u001b[1;32m    250\u001b[0m init_carry \u001b[39m=\u001b[39m CarryType(key\u001b[39m=\u001b[39mkey, live_points\u001b[39m=\u001b[39mlive_points, log_L_contour\u001b[39m=\u001b[39mlog_L_contour)\n\u001b[1;32m    251\u001b[0m init_X \u001b[39m=\u001b[39m live_points\u001b[39m.\u001b[39mreservoir\u001b[39m.\u001b[39mlog_L\n\u001b[0;32m--> 252\u001b[0m (_, live_points, log_L_contour), dead_reservoir \u001b[39m=\u001b[39m scan(body, init_carry, init_X)\n\u001b[1;32m    253\u001b[0m \u001b[39mreturn\u001b[39;00m (dead_reservoir, live_points, log_L_contour)\n","    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:239\u001b[0m, in \u001b[0;36mStaticNestedSampler._single_live_point_shrink.<locals>.body\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m# replace dead point with a new sample about contour\u001b[39;00m\n\u001b[1;32m    237\u001b[0m key, sample_key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(carry\u001b[39m.\u001b[39mkey, \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 239\u001b[0m sample \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49mget_sample(key\u001b[39m=\u001b[39;49msample_key,\n\u001b[1;32m    240\u001b[0m                             log_L_constraint\u001b[39m=\u001b[39;49mlog_L_contour,\n\u001b[1;32m    241\u001b[0m                             live_points\u001b[39m=\u001b[39;49mcarry\u001b[39m.\u001b[39;49mlive_points,\n\u001b[1;32m    242\u001b[0m                             preprocess_data\u001b[39m=\u001b[39;49mpreprocess_data)\n\u001b[1;32m    244\u001b[0m live_points_reservoir \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m old, update: old\u001b[39m.\u001b[39mat[idx_min]\u001b[39m.\u001b[39mset(update),\n\u001b[1;32m    245\u001b[0m                                  carry\u001b[39m.\u001b[39mlive_points\u001b[39m.\u001b[39mreservoir, Reservoir(\u001b[39m*\u001b[39msample))\n\u001b[1;32m    246\u001b[0m live_points \u001b[39m=\u001b[39m carry\u001b[39m.\u001b[39mlive_points\u001b[39m.\u001b[39m_replace(reservoir\u001b[39m=\u001b[39mlive_points_reservoir)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/static_nested_sampler.py:155\u001b[0m, in \u001b[0;36mMarkovSampler.get_sample\u001b[0;34m(self, key, log_L_constraint, live_points, preprocess_data)\u001b[0m\n\u001b[1;32m    153\u001b[0m key, seed_key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msplit(key, \u001b[39m2\u001b[39m)\n\u001b[1;32m    154\u001b[0m seed_point \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_seed_point(key\u001b[39m=\u001b[39mseed_key, live_points\u001b[39m=\u001b[39mlive_points, log_L_constraint\u001b[39m=\u001b[39mlog_L_constraint)\n\u001b[0;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_sample_from_seed(key\u001b[39m=\u001b[39;49mkey, seed_point\u001b[39m=\u001b[39;49mseed_point, log_L_constraint\u001b[39m=\u001b[39;49mlog_L_constraint,\n\u001b[1;32m    156\u001b[0m                                  preprocess_data\u001b[39m=\u001b[39;49mpreprocess_data)\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jaxns/slice_samplers.py:302\u001b[0m, in \u001b[0;36mUniDimSliceSampler.get_sample_from_seed\u001b[0;34m(self, key, seed_point, log_L_constraint, preprocess_data)\u001b[0m\n\u001b[1;32m    299\u001b[0m     (proposal_state, _) \u001b[39m=\u001b[39m body_state\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mless(proposal_state\u001b[39m.\u001b[39mproposal_count, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_slices)\n\u001b[0;32m--> 302\u001b[0m (proposal_state, log_L) \u001b[39m=\u001b[39m while_loop(slice_sampler_cond,\n\u001b[1;32m    303\u001b[0m                                      slice_sampler_body,\n\u001b[1;32m    304\u001b[0m                                      (init_proposal_state, \u001b[39m-\u001b[39;49mjnp\u001b[39m.\u001b[39;49minf))\n\u001b[1;32m    305\u001b[0m \u001b[39m# when num_slices==0, that means we don't want to run this\u001b[39;00m\n\u001b[1;32m    306\u001b[0m pass_through \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_slices \u001b[39m==\u001b[39m jnp\u001b[39m.\u001b[39mzeros_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_slices)\n","    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n","File \u001b[0;32m~/opt/anaconda3/envs/Stingproj/lib/python3.11/site-packages/jax/_src/lax/control_flow/common.py:202\u001b[0m, in \u001b[0;36m_check_tree_and_avals\u001b[0;34m(what, tree1, avals1, tree2, avals2)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mmap\u001b[39m(core\u001b[39m.\u001b[39mtypematch, avals1, avals2)):\n\u001b[1;32m    200\u001b[0m   diff \u001b[39m=\u001b[39m tree_map(_show_diff, tree_unflatten(tree1, avals1),\n\u001b[1;32m    201\u001b[0m                   tree_unflatten(tree2, avals2))\n\u001b[0;32m--> 202\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mwhat\u001b[39m}\u001b[39;00m\u001b[39m must have identical types, got\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiff\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: body_fun output and input must have identical types, got\n(UniDimProposalState(key='ShapedArray(uint32[2])', process_step='ShapedArray(int32[])', proposal_count='ShapedArray(int32[])', num_likelihood_evaluations='ShapedArray(int32[])', point_U0='ShapedArray(float32[5])', log_L0='ShapedArray(float32[])', direction='ShapedArray(float32[5])', left='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', right='DIFFERENT ShapedArray(float64[]) vs. ShapedArray(float32[])', point_U='ShapedArray(float32[5])', t='ShapedArray(float32[])', log_L_constraint='ShapedArray(float32[])'), 'ShapedArray(float32[])')."]}],"source":["# Gpresult = GPResult(Lightcurve(time = Times, counts = counts, dt = Times[1]- Times[0]))\n","# Gpresult.sample(prior_model = prior_model, likelihood_model = likelihood_model)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Plotting functions testing\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
